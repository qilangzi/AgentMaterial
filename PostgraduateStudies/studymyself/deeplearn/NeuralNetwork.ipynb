{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 神经网络\n",
    "- 有监督问题\n",
    "- 主要的优势是可以提取数据集中最优的特征，让机器智能地学习\n",
    "- 主要用于计算机视觉和自然语言处理\n",
    "- 视觉数据库：www.image-net.org\n",
    "    - 小数据集：cifar-10 \n",
    "- 语言数据库：www.mpi-sws.org/~cristian/coco.html\n",
    "- 适用范围（数据庞大）\n",
    "    - 数据集小：深度学习和机器学习差不多\n",
    "    - 数据集大（上万的数据集）：神经网络有优势 \n",
    "## K近邻\n",
    "- 计算流程\n",
    "    - 计算已知类别数据集中的点与当前点的距离\n",
    "    - 按照距离依次排序\n",
    "    - 选取与当前点距离最小的 K 个点\n",
    "    - 确定前 K 个点所在类别的出现概率\n",
    "    - 返回前 K 个点出现频率最高的类别作为当前点预测分类\n",
    "- 分析    \n",
    "    - KNN 算法本身简单有效，它是一种 lazy-learning 算法。\n",
    "    - 分类器不需要使用训练集进行训练，训练时间复杂度为 0。\n",
    "    - KNN 分类的计算复杂度和训练集中的文档数目成正比，也就是说，如果训练集中文档总数为 n，那么 KNN 的分类时间复杂度为 O (n)\n",
    "    - K 值的选择，距离度量和分类决策规则是该算法的三个基本要素\n",
    "- ![](../img/img_11.png)"
   ],
   "id": "49e430d52505df7a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 得分函数\n",
    "- $f(x,W)= Wx +b $ x为特征，W为权重，b为偏置\n",
    "- 区别：x的分类有几种，W就有多少种，算每种对应的得分，例如一个测试图片它为猫的得分是多少，狗的得分多少，猪的得分是多少\n",
    "- ![](../img/img_12.png)\n",
    "- 损失函数：\n",
    " - $ L_i = \\sum_{j \\neq y_i} \\max(0, s_j - s_{y_i} + 1) $ 其中$ s_j $为第i个样本的错误得分，$ s_{y_i} $为第i个样本的正确得分，1为容忍程度（可调节）\n",
    "- 添加惩罚项后改进为\n",
    "    - $L = \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j \\neq y_i} \\max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + 1) + \\lambda R(W)$\n",
    "    - $R(W) = \\sum_{k} \\sum_{l} W_{k,l}^2$\n",
    "- softmax分类器\n",
    "    - $ P(Y = k | X = x_i) = \\frac{e^{s_k}}{\\sum_j e^{s_j}} \\quad \\text{where} \\quad s = f(x_i; W) $\n",
    "    - $ L_i = -\\log P(Y = y_i | X = x_i) $\n",
    "- 前向传播\n",
    "    - 通过向前计算，最后得到损失\n",
    "- 反向传播\n",
    "    - 通过损失函数，反向计算到权重 \n",
    "- 神经网络：\n",
    "    - 演示网站：http://cs.stanford/edu/people/karpathy/conventjs/demo/classify2d.html \n",
    "    - 基本机构：$f=W_2 max(0,W_1 x)$\n",
    "    - 继续堆叠一层：$f=W_3 max(0,W_2 max(0,W_1 x))$\n",
    "- 激活函数：\n",
    "    - sigmoid: $f(x) = \\frac{1}{1+e^{-x}}$ 原因在一些时梯度为0，容易导致梯度消失，是神经元停止传播\n",
    "    - Relu: $f(x) = max(0,x)$ 不会出现梯度为0的情况，用的比较多\n",
    "- 防止过拟合\n",
    "    - DROP-OUT ：在训练过程中，将一部分神经元“断掉”（每一层断掉不同的），从而防止过拟合。 "
   ],
   "id": "876f8531a7b3e38c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:43:10.595140Z",
     "start_time": "2025-07-27T11:43:10.476252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# from utils.features import prepare_for_training\n"
   ],
   "id": "44c290ceab873b77",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron:\n",
    "    def __init__(self, data,labels,layers,normalize_data=False):\n",
    "        data_processed = prepare_for_training(data,normalize_data=normalize_data)\n",
    "        self.data = data_processed\n",
    "        self.labels = labels\n",
    "        self.layers = layers\n",
    "        self.normalize_data=normalize_data\n",
    "        self.thetas=MultiLayerPerceptron.thetas_init(layers)\n",
    "    @staticmethod    \n",
    "    def thetas_init(layers):\n",
    "        thetas = []\n",
    "        for i in range(len(layers)-1):\n",
    "            theta = np.random.randn(layers[i+1],layers[i]+1)\n",
    "            thetas.append(theta)\n",
    "        return thetas"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4637c318ab9ce53d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
